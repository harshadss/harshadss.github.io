<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">

<meta itemprop="name" content="When (not) to use deep learning">
<meta itemprop="description" content="I&rsquo;ve documented my disdain for using &lsquo;deep learning as a hammer looking for nails in every corner&rsquo; in few other entries on this blog. Taking a less cynical and acerbic view, I want to focus on when deep learning can be a good starting point and when it is not useful as starting point.
First to clarify bit of terminology. Deep learning is a catch-all term used in popular data science these days.">


<meta itemprop="datePublished" content="2018-09-10T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-09-10T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="569">



<meta itemprop="keywords" content="machine learning,deep learning," />
<meta property="og:title" content="When (not) to use deep learning" />
<meta property="og:description" content="I&rsquo;ve documented my disdain for using &lsquo;deep learning as a hammer looking for nails in every corner&rsquo; in few other entries on this blog. Taking a less cynical and acerbic view, I want to focus on when deep learning can be a good starting point and when it is not useful as starting point.
First to clarify bit of terminology. Deep learning is a catch-all term used in popular data science these days." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://harshadss.github.io/posts/when_to_use_deep_learning/" />
<meta property="article:published_time" content="2018-09-10T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2018-09-10T00:00:00&#43;00:00"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="When (not) to use deep learning"/>
<meta name="twitter:description" content="I&rsquo;ve documented my disdain for using &lsquo;deep learning as a hammer looking for nails in every corner&rsquo; in few other entries on this blog. Taking a less cynical and acerbic view, I want to focus on when deep learning can be a good starting point and when it is not useful as starting point.
First to clarify bit of terminology. Deep learning is a catch-all term used in popular data science these days."/>

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>When (not) to use deep learning</title>
	<link rel="stylesheet" href="https://harshadss.github.io/css/style.min.31706917653d2b9e8410abd431f30ec4359a88a94fc87a63654779d87329edec.css" integrity="sha256-MXBpF2U9K56EEKvUMfMOxDWaiKlPyHpjZUd52HMp7ew=">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp faster">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://harshadss.github.io/">Harshad Saykhedkar</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					<a href="https://harshadss.github.io/posts/">Posts</a>
					<a href="https://harshadss.github.io/about-harshad-saykhedkar/">About</a>
				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<span class="hdr-social hide-in-mobile"><a href="https://twitter.com/harshad_geek" target="_blank" rel="noopener me" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg></a><a href="https://github.com/harshadss" target="_blank" rel="noopener me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://harshadss.github.io/posts/">Posts</a></li>
			<li><a href="https://harshadss.github.io/about-harshad-saykhedkar/">About</a></li>
		</ul>
	</div>


	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Sep 10, 2018</span></div>
				<h1>When (not) to use deep learning</h1>
			</header>
			<div class="content">
				

<p>I&rsquo;ve documented my disdain for using &lsquo;deep learning as a hammer looking for nails in every corner&rsquo;
in few other entries on this blog. Taking a less cynical and acerbic view, I want to focus on
when deep learning can be a good starting point and when it is not useful as starting point.</p>

<p>First to clarify bit of terminology. Deep learning is a catch-all term used in popular data science
these days. But we must separate out what this term encompases. It covers the following broad ideas,</p>

<ol>
<li>Novel neural network architectures tailored for specific applications (example: LSTMs in language)</li>
<li>Innovations at algorithmic (example: adam optimizer) and component (example: GELU non-linearity) level
 for improving performance of optimization algorithms which find weights for neural network.</li>
<li>Engineering discipline which tries to solve for problems in 1-2 at hardware (GPUs and TPUs) and
 coding abstractions (example: auto-grad, libraries) level.</li>
</ol>

<p>This post is focussed on (1).</p>

<h3 id="when-deep-learning-is-a-bad-choice">When Deep Learning is a Bad Choice<a href="#when-deep-learning-is-a-bad-choice" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<ol>
<li>If the base representation of your data as seen by a computer and by a human is almost the same.</li>
<li>When the data consists of mostly heterogeneous pieces of information.</li>
</ol>

<p>For example, consider problem of predicting whether a customer will default on a loan or not. The data
will be a mix of demographics, details about the product offering (interest rates, amount), customer&rsquo;s
repayment history with same bank and so on. Most of the columns in such a dataset are measured on different
scale and they represent completely different things. For such problems, human beings cannot spot
decision rules or features just by looking at data. I&rsquo;ve found that random-forest and gradient boosting methods
often give respectable and easy to use start on such problem. Note that I&rsquo;m not arguing that random forest will
always outperform carefully tuned neural network applied to such problems. Rather, I&rsquo;m saying that random-forest
kind of algorithms are safe choice which will give you good accuracy without much effort. Only after you&rsquo;ve
established a good baseline with RFs and you are convinced that the baseline is absolute disaster should you
consider other ideas like deep learning. Deep learning may come into picture when your feature engineering can&rsquo;t
keep up with evolution of problem complexity. <a href="https://eng.lyft.com/fingerprinting-fraudulent-behavior-6663d0264fad">Check out this post on fraud detection at Lyft for one example</a></p>

<h3 id="when-deep-learning-is-a-good-choice">When Deep Learning is a Good Choice<a href="#when-deep-learning-is-a-good-choice" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>

<ol>
<li>If base representation of your data as seen by a computer and by a human is radically different.</li>
<li>Data consists mostly of homogeneous pieces of information.</li>
</ol>

<p>Consider images, a five year old child can routinely distinguish between a cat and a dog image. On the other
hand, a computer only sees bunch of pixels. The gap between representation and features is too large. Also,
the data is homogeneous: everything is an integer value representing intensity at pixel. Similarly, language
applications. To the computer, the base representation is just a sequence of unicodes. But we human beings
can quickly see patterns, meanings. Again the data is homogeneous (sequence of integers representing unicode
points) and gap between representation of information and meaning of information is too large. In such applications,
you effectively want the computer to learn to represent knowledge (for a limited domain) first, the classification
model is secondary. Deep learning seems to be excelling at such applications. There are few people who infact refer
to deep learning as representation learning.</p>

<p>Hopefully, this post gives a good thumb rule on applying deep learning.</p>

			</div>
			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://harshadss.github.io/tags/machine-learning">machine learning</a></span><span class="tag"><a href="https://harshadss.github.io/tags/deep-learning">deep learning</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>569 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2018-09-10 05:30 &#43;0530</p>
			</footer>
		</article>
		<div class="post-nav thin">
			<a class="next-post" href="https://harshadss.github.io/posts/found_interesting_link_introduction/">
				<span class="post-nav-label"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg>&nbsp;Newer</span><br><span>Found interesting link: Introduction</span>
			</a>
			<a class="prev-post" href="https://harshadss.github.io/posts/where_ai_will_change_world/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>Where AI will Change World</span>
			</a>
		</div>
		<div id="comments" class="thin">
</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2020 <a href="https://harshadss.github.io/">Harshad Saykhedkar</a> Copyright Harshad Saykhedkar</p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="https://harshadss.github.io/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>


	<script src="https://harshadss.github.io/js/main.min.784417f5847151f848c339cf0acb13a06cbb648b1483435a28ed4556c4ead69b.js" integrity="sha256-eEQX9YRxUfhIwznPCssToGy7ZIsUg0NaKO1FVsTq1ps="></script>

</body>

</html>
